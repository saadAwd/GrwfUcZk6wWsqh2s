{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# import necessary libraries\nimport pandas as pd\nfrom sklearn.feature_selection import SelectKBest, chi2\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import roc_auc_score\n\n\n# load the dataset\ndata = pd.read_csv('/kaggle/input/acme-happiness/ACME-HappinessSurvey2020.csv')\n\n# split the dataset into training and testing sets\nX = data.drop('Y', axis=1)\ny = data['Y']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# select the top 3 features using SelectKBest\nselector = SelectKBest(score_func=chi2, k=3)\nX_train_new = selector.fit_transform(X_train, y_train)\nX_test_new = selector.transform(X_test)\n\n# create a logistic regression model\nmodel = LogisticRegression()\n\n# train the model on the training data using the top 3 features\nmodel.fit(X_train_new, y_train)\n\n# predict the happiness level for the testing data using the top 3 features\ny_pred = model.predict(X_test_new)\n\n# evaluate the accuracy of the model using the top 3 features\naccuracy = model.score(X_test_new, y_test)\nprint('Accuracy:', accuracy)\n\n# evaluate the f1 score of the model using the top 3 features\nf1 = f1_score(y_test, y_pred)\nprint('F1 Score:', f1)\n\n#AUC\nROC_AUC = roc_auc_score(y_test, y_pred)\n\nprint('ROC AUC : {:.4f}'.format(ROC_AUC))\n\n# print the top 3 features\nfeature_scores = pd.DataFrame({'Feature': X_train.columns, 'Score': selector.scores_})\ntop_features = feature_scores.nlargest(3, 'Score')\nprint('Top 3 Features:', top_features['Feature'].tolist())","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-09T10:34:04.387443Z","iopub.execute_input":"2023-04-09T10:34:04.387776Z","iopub.status.idle":"2023-04-09T10:34:05.949826Z","shell.execute_reply.started":"2023-04-09T10:34:04.387749Z","shell.execute_reply":"2023-04-09T10:34:05.948397Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Accuracy: 0.46153846153846156\nF1 Score: 0.5\nROC AUC : 0.4848\nTop 3 Features: ['X1', 'X5', 'X2']\n","output_type":"stream"}]},{"cell_type":"code","source":"# import necessary libraries\nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import roc_auc_score\n\n\n# load the dataset\ndata = pd.read_csv('/kaggle/input/acme-happiness/ACME-HappinessSurvey2020.csv')\n\n# split the dataset into training and testing sets\nX = data.drop('Y', axis=1)\ny = data['Y']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# create a logistic regression model\nmodel = LogisticRegression()\n\n# train the model on the training data\nmodel.fit(X_train, y_train)\n\n# predict the happiness level for the testing data\ny_pred = model.predict(X_test)\n\n# evaluate the f1 score of the model using the top 3 features\nf1 = f1_score(y_test, y_pred)\nprint('F1 Score:', f1)\n\n#AUC\nROC_AUC = roc_auc_score(y_test, y_pred)\n\nprint('ROC AUC : {:.4f}'.format(ROC_AUC))\n\n# evaluate the accuracy of the model\naccuracy = model.score(X_test, y_test)\nprint('Accuracy:', accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-04-06T10:11:36.691373Z","iopub.execute_input":"2023-04-06T10:11:36.691802Z","iopub.status.idle":"2023-04-06T10:11:36.734897Z","shell.execute_reply.started":"2023-04-06T10:11:36.691762Z","shell.execute_reply":"2023-04-06T10:11:36.733422Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"F1 Score: 0.5\nROC AUC : 0.4848\nAccuracy: 0.46153846153846156\n","output_type":"stream"}]},{"cell_type":"code","source":"# import necessary libraries\nimport pandas as pd\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import roc_auc_score\n\n\n# load the dataset\ndata = pd.read_csv('/kaggle/input/acme-happiness/ACME-HappinessSurvey2020.csv')\n\n# split the dataset into training and testing sets\nX = data.drop('Y', axis=1)\ny = data['Y']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# create a decision tree classifier model\nmodel = DecisionTreeClassifier()\n\n# train the model on the training data using the best 3 features\nmodel.fit(X_train, y_train)\n\n# predict the happiness level for the testing data using the best 3 features\ny_pred = model.predict(X_test)\n\n# evaluate the f1 score of the model using the top 3 features\nf1 = f1_score(y_test, y_pred)\nprint('F1 Score:', f1)\n\n#AUC\nROC_AUC = roc_auc_score(y_test, y_pred)\n\nprint('ROC AUC : {:.4f}'.format(ROC_AUC))\n\n# evaluate the accuracy of the model using the best 3 features\naccuracy = model.score(X_test, y_test)\nprint('Accuracy:', accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-06T10:11:42.802161Z","iopub.execute_input":"2023-04-06T10:11:42.802545Z","iopub.status.idle":"2023-04-06T10:11:42.827985Z","shell.execute_reply.started":"2023-04-06T10:11:42.802509Z","shell.execute_reply":"2023-04-06T10:11:42.827002Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"F1 Score: 0.64\nROC AUC : 0.6636\nAccuracy: 0.6538461538461539\n","output_type":"stream"}]},{"cell_type":"code","source":"# import necessary libraries\nimport pandas as pd\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import SelectKBest, chi2\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import roc_auc_score\n\n\n# load the dataset\ndata = pd.read_csv('/kaggle/input/acme-happiness/ACME-HappinessSurvey2020.csv')\n\n# split the dataset into training and testing sets\nX = data.drop('Y', axis=1)\ny = data['Y']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# select the top 3 features using SelectKBest\nselector = SelectKBest(score_func=chi2, k=3)\nX_train_new = selector.fit_transform(X_train, y_train)\nX_test_new = selector.transform(X_test)\n\n# create a decision tree classifier model\nmodel = DecisionTreeClassifier()\n\n# train the model on the training data using the top 3 features\nmodel.fit(X_train_new, y_train)\n\n# predict the happiness level for the testing data using the top 3 features\ny_pred = model.predict(X_test_new)\n\n# evaluate the accuracy of the model using the top 3 features\naccuracy = model.score(X_test_new, y_test)\nprint('Accuracy:', accuracy)\n\n# evaluate the f1 score of the model using the top 3 features\nf1 = f1_score(y_test, y_pred)\nprint('F1 Score:', f1)\n\n#AUC\nROC_AUC = roc_auc_score(y_test, y_pred)\n\nprint('ROC AUC : {:.4f}'.format(ROC_AUC))\n\n\n# print the top 3 features\nfeature_scores = pd.DataFrame({'Feature': X_train.columns, 'Score': selector.scores_})\ntop_features = feature_scores.nlargest(3, 'Score')\nprint('Top 3 Features:', top_features['Feature'].tolist())","metadata":{"execution":{"iopub.status.busy":"2023-04-06T10:10:37.444617Z","iopub.execute_input":"2023-04-06T10:10:37.445041Z","iopub.status.idle":"2023-04-06T10:10:37.475217Z","shell.execute_reply.started":"2023-04-06T10:10:37.445005Z","shell.execute_reply":"2023-04-06T10:10:37.473943Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Accuracy: 0.7307692307692307\nF1 Score: 0.6956521739130435\nROC AUC : 0.7303\nTop 3 Features: ['X1', 'X5', 'X2']\n","output_type":"stream"}]},{"cell_type":"code","source":"# import necessary libraries\nimport pandas as pd\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import SelectKBest, chi2\nfrom sklearn.metrics import roc_auc_score\n\n# load the dataset\ndata = pd.read_csv('/kaggle/input/acme-happiness/ACME-HappinessSurvey2020.csv')\n\n# split the dataset into training and testing sets\nX = data.drop('Y', axis=1)\ny = data['Y']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# select the top 3 features using SelectKBest\nselector = SelectKBest(score_func=chi2, k=3)\nX_train_new = selector.fit_transform(X_train, y_train)\nX_test_new = selector.transform(X_test)\n\n# create a decision tree classifier model using Gini index\nmodel_gini = DecisionTreeClassifier(criterion='gini')\n\n# train the model on the training data using the top 3 features\nmodel_gini.fit(X_train_new, y_train)\n\n# predict the happiness level for the testing data using the top 3 features\ny_pred_gini = model_gini.predict(X_test_new)\n\n# evaluate the accuracy of the model using Gini index and the top 3 features\naccuracy_gini = model_gini.score(X_test_new, y_test)\nprint('Accuracy (Gini index):', accuracy_gini)\n\n# create a decision tree classifier model using entropy\nmodel_entropy = DecisionTreeClassifier(criterion='entropy')\n\n# train the model on the training data using the top 3 features\nmodel_entropy.fit(X_train_new, y_train)\n\n# predict the happiness level for the testing data using the top 3 features\ny_pred_entropy = model_entropy.predict(X_test_new)\n\n# evaluate the accuracy of the model using entropy and the top 3 features\naccuracy_entropy = model_entropy.score(X_test_new, y_test)\nprint('Accuracy (Entropy):', accuracy_entropy)\n\n#AUC\nROC_AUC = roc_auc_score(y_test, y_pred)\n\nprint('ROC AUC : {:.4f}'.format(ROC_AUC))\n\n\n# print the top 3 features\nfeature_scores = pd.DataFrame({'Feature': X_train.columns, 'Score': selector.scores_})\ntop_features = feature_scores.nlargest(3, 'Score')\nprint('Top 3 Features:', top_features['Feature'].tolist())","metadata":{"execution":{"iopub.status.busy":"2023-04-06T10:10:22.477944Z","iopub.execute_input":"2023-04-06T10:10:22.478341Z","iopub.status.idle":"2023-04-06T10:10:22.513178Z","shell.execute_reply.started":"2023-04-06T10:10:22.478308Z","shell.execute_reply":"2023-04-06T10:10:22.511865Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Accuracy (Gini index): 0.7307692307692307\nAccuracy (Entropy): 0.7307692307692307\nROC AUC : 0.6030\nTop 3 Features: ['X1', 'X5', 'X2']\n","output_type":"stream"}]},{"cell_type":"code","source":"# import necessary libraries\nimport pandas as pd\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import SelectKBest, chi2\nfrom sklearn.metrics import roc_auc_score\n\n# load the dataset\ndata = pd.read_csv('/kaggle/input/acme-happiness/ACME-HappinessSurvey2020.csv')\n\n# split the dataset into training and testing sets\nX = data.drop('Y', axis=1)\ny = data['Y']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n\n# create a decision tree classifier model using Gini index\nmodel_gini = DecisionTreeClassifier(criterion='gini')\n\n# train the model on the training data using the top 3 features\nmodel_gini.fit(X_train, y_train)\n\n# predict the happiness level for the testing data using the top 3 features\ny_pred_gini = model_gini.predict(X_test)\n\n# evaluate the accuracy of the model using Gini index and the top 3 features\naccuracy_gini = model_gini.score(X_test, y_test)\nprint('Accuracy (Gini index):', accuracy_gini)\n\n# create a decision tree classifier model using entropy\nmodel_entropy = DecisionTreeClassifier(criterion='entropy')\n\n# train the model on the training data using the top 3 features\nmodel_entropy.fit(X_train, y_train)\n\n# predict the happiness level for the testing data using the top 3 features\ny_pred_entropy = model_entropy.predict(X_test)\n\n# evaluate the accuracy of the model using entropy and the top 3 features\naccuracy_entropy = model_entropy.score(X_test, y_test)\nprint('Accuracy (Entropy):', accuracy_entropy)\n\n#AUC\nROC_AUC = roc_auc_score(y_test, y_pred)\n\nprint('ROC AUC : {:.4f}'.format(ROC_AUC))\n","metadata":{"execution":{"iopub.status.busy":"2023-04-06T10:09:53.849147Z","iopub.execute_input":"2023-04-06T10:09:53.849540Z","iopub.status.idle":"2023-04-06T10:09:53.880415Z","shell.execute_reply.started":"2023-04-06T10:09:53.849505Z","shell.execute_reply":"2023-04-06T10:09:53.879202Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Accuracy (Gini index): 0.6538461538461539\nAccuracy (Entropy): 0.6538461538461539\nROC AUC : 0.6030\n","output_type":"stream"}]},{"cell_type":"code","source":"# import necessary libraries\n\nimport pandas as pd\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import SelectKBest, f_regression\nfrom sklearn.metrics import roc_auc_score\n\n# load the dataset\ndata = pd.read_csv('/kaggle/input/acme-happiness/ACME-HappinessSurvey2020.csv')\n\n# split the dataset into training and testing sets\nX = data.drop('Y', axis=1)\ny = data['Y']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# select the top 3 features using SelectKBest\nselector = SelectKBest(score_func=f_regression, k=3)\nX_train_new = selector.fit_transform(X_train, y_train)\nX_test_new = selector.transform(X_test)\n\n# create a decision tree regressor model\nmodel = DecisionTreeRegressor()\n\n# train the model on the training data using the top 3 features\nmodel.fit(X_train_new, y_train)\n\n# predict the happiness level for the testing data using the top 3 features\ny_pred = model.predict(X_test_new)\n\n\n#AUC\nROC_AUC = roc_auc_score(y_test, y_pred)\n\nprint('ROC AUC : {:.4f}'.format(ROC_AUC))\n\n# print the top 3 features\nfeature_scores = pd.DataFrame({'Feature': X_train.columns, 'Score': selector.scores_})\ntop_features = feature_scores.nlargest(3, 'Score')\nprint('Top 3 Features:', top_features['Feature'].tolist())","metadata":{"execution":{"iopub.status.busy":"2023-04-06T10:09:31.134990Z","iopub.execute_input":"2023-04-06T10:09:31.135746Z","iopub.status.idle":"2023-04-06T10:09:31.167011Z","shell.execute_reply.started":"2023-04-06T10:09:31.135691Z","shell.execute_reply":"2023-04-06T10:09:31.165616Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"ROC AUC : 0.6030\nTop 3 Features: ['X1', 'X6', 'X5']\n","output_type":"stream"}]}]}